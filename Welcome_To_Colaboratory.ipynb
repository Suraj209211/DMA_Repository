{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suraj209211/DMA_Repository/blob/main/Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Sample data\n",
        "corpus = [\n",
        "    (\"I love this movie, it's fantastic!\", \"positive\"),\n",
        "    (\"The acting was terrible, I hated it.\", \"negative\"),\n",
        "    (\"Great plot and characters, highly recommend.\", \"positive\"),\n",
        "    (\"The worst movie I've ever seen, don't waste your time.\", \"negative\"),\n",
        "    (\"I enjoyed every moment of this film.\", \"positive\"),\n",
        "    (\"Disappointing and boring, not worth watching.\", \"negative\")\n",
        "]\n",
        "\n",
        "# Separate data into features and labels\n",
        "X, y = zip(*corpus)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a bag-of-words representation of the text data\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_counts = vectorizer.fit_transform(X_train)\n",
        "X_test_counts = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Multinomial Naive Bayes classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_counts, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = clf.predict(X_test_counts)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Display classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRJHnv2ZhqPo",
        "outputId": "9c1d849d-8360-460c-be71-4859bdc16bbb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00         1\n",
            "    positive       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate synthetic Iris data\n",
        "num_samples = 150\n",
        "sepal_length = np.random.normal(loc=5.84, scale=0.83, size=num_samples)\n",
        "sepal_width = np.random.normal(loc=3.06, scale=0.43, size=num_samples)\n",
        "petal_length = np.random.normal(loc=3.76, scale=1.76, size=num_samples)\n",
        "petal_width = np.random.normal(loc=1.20, scale=0.76, size=num_samples)\n",
        "\n",
        "# Create labels for three species: 0, 1, 2\n",
        "species = np.random.choice([0, 1, 2], size=num_samples)\n",
        "\n",
        "# Create a DataFrame\n",
        "iris_data = pd.DataFrame({\n",
        "    'sepal_length': sepal_length,\n",
        "    'sepal_width': sepal_width,\n",
        "    'petal_length': petal_length,\n",
        "    'petal_width': petal_width,\n",
        "    'species': species\n",
        "})\n",
        "\n",
        "# Display the first few rows of the synthetic Iris dataset\n",
        "print(iris_data.head())\n",
        "\n",
        "# Save the dataset to a CSV file (optional)\n",
        "iris_data.to_csv('synthetic_iris_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "id": "oSJ614fXh6wY",
        "outputId": "15d0731d-95a1-46cb-c822-d94c88b8f8f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width  species\n",
            "0      6.252273     3.167712      2.300969     1.152364        2\n",
            "1      5.725241     3.208973      2.774081     1.925908        0\n",
            "2      6.377581     2.767589      5.075237     0.450848        1\n",
            "3      7.104115     3.159869      4.834252     1.583075        2\n",
            "4      5.645653     3.186021      3.723213     0.797004        2\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}